{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem(grammar_info=False, disambiguation=False)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## импорт и обработка таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"8.xlsx\") # данные для обучения (уточнить адрес)\n",
    "df2 = pd.read_excel(\"9.xlsx\") # Данные для предсказания (уточнить адрес)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) при токенизации удаляются знаки препинания\n",
    "# 2) Слова ставятся в начальную форму, записываются в строку через пробел\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"текст\"] = [tokenizer.tokenize(n) for n in df[\"текст\"]]\n",
    "df[\"текст\"] = [' '.join(n) for n in df[\"текст\"]]\n",
    "df[\"текст\"] = [mystem_analyzer.lemmatize(n) for n in df[\"текст\"]]\n",
    "# сохраняем копию списка лемматизированных слов\n",
    "#vocab = df[[\"текст\"]].copy() - из старого кода\n",
    "df[\"текст\"] = [''.join(n) for n in df[\"текст\"]]\n",
    "\n",
    "df2[\"текст\"] = [tokenizer.tokenize(n) for n in df2[\"текст\"]]\n",
    "df2[\"текст\"] = [' '.join(n) for n in df2[\"текст\"]]\n",
    "df2[\"текст\"] = [mystem_analyzer.lemmatize(n) for n in df2[\"текст\"]]\n",
    "# сохраняем копию списка лемматизированных слов\n",
    "#vocab2 = df2[[\"текст\"]].copy() - из старого кода\n",
    "df2[\"текст\"] = [''.join(n) for n in df2[\"текст\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_txt = df2[\"текст\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визирование таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычленение ключевых слов (выполнить 1 раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in df[\"ключевые слова\"].tolist():\n",
    "    sentence = str(sentence).replace(\"\\t\", \"\") #удаляем лишнее из данных для обучения\n",
    "    sentence = sentence.replace(\",\", \", \")\n",
    "    sentence = sentence.replace(\"  \", \" \")\n",
    "    sentence = sentence.replace(\"  \", \" \")\n",
    "    sentence = sentence.split(\", \") #разделяем набор ключевых слов\n",
    "    for word in sentence: #добавляем в список уникальные значения ключевых слов\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.most_common()[:-400-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = c.most_common(400)\n",
    "words = [n[0] for n in words]\n",
    "words[-1:-100:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## функция предсказания для 1 ключевого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Klslovo(a):\n",
    "    answerlist = []\n",
    "    for n in df['ключевые слова'].tolist():\n",
    "        x = a in str(n)\n",
    "        answerlist.append(int(x))\n",
    "    df[\"ответ\"] = answerlist #создаём новую колонку в таблице: она содержит единицы в строках, где есть ключевое слово\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], \\\n",
    "                            df.iloc[:,-1].tolist(), \\\n",
    "                            test_size=0.1, \\\n",
    "                            random_state=42)\n",
    "    X_train = X_train[\"текст\"] # учимся на колонке с текстом\n",
    "    X_test = X_test[\"текст\"] # учимся на колонке с текстом\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(ngram_range=(1, 2))),#уточнить, нужны ли н-граммы\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(penalty=\"l2\", class_weight=\"balanced\", solver=\"liblinear\")),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    prediction = pipeline.predict(X_test)\n",
    "    print(\"\\n\" + \"для слова \" + a + \" результаты прогноза:\")\n",
    "    precision = precision_score(y_true=y_test, y_pred=prediction, average=\"macro\")\n",
    "    print(\"precision = \" + str(precision))\n",
    "    recall = recall_score(y_true=y_test, y_pred=prediction, average=\"macro\")\n",
    "    print(\"recall = \" + str(recall))\n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=prediction)\n",
    "    print(\"accuracy = \" + str(accuracy))\n",
    "    f1 = f1_score(y_true=y_test, y_pred=prediction, average=\"macro\")\n",
    "    print(\"f1 = \" + str(f1))\n",
    "    return a, pipeline.predict(X_pred_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_Word, first_Answer = Klslovo(words[0])\n",
    "#for n in np.where(first_Answer == 1):\n",
    "#    df2.loc[n, \"ключевые слова\"] = str(first_Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulti = []\n",
    "for n in range(len(X_pred_txt)):\n",
    "    resulti.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция записи ключевых слов в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writedown(a, answers):\n",
    "    for n in np.where(answers == 1)[0]:\n",
    "        resulti[int(n)].append(a)\n",
    "# остатки старого кода:\n",
    "#        if type(df2.loc[n, \"ключевые слова\"]) is float == True:\n",
    "#            df2.loc[n, \"ключевые слова\"] = str(a)\n",
    "#            print(\"1\")\n",
    "#        elif type(df2.loc[n, \"ключевые слова\"]) is str == True:\n",
    "#            df2.loc[n, \"ключевые слова\"] = df2.loc[n, \"ключевые слова\"] + \", \" + a\n",
    "#            print(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение функций ко всем словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in words:\n",
    "    results = Klslovo(n)\n",
    "    writedown(results[0], results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulti[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulti2 = [\", \".join(n) for n in resulti]\n",
    "resulti2[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## запись в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"ключевые слова\"] = pd.Series(resulti2)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(\"13.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
